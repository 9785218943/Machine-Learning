{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9a153-ad53-4cdc-b3e2-2128ffce589c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fa8c175-1c99-49cb-8af7-7df432b06fc9",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use thecompany's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47e602b9-447f-4436-b067-486d58fae18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_A = 0.70  # Probability that an employee uses the health insurance plan\n",
    "P_B_given_A = 0.40  # Probability that an employee is a smoker given that they use the health insurance plan\n",
    "\n",
    "# We need to calculate P(B), the overall probability that an employee is a smoker\n",
    "# However, we don't have P(B|¬A), so we'll assume a reasonable value for the sake of calculation\n",
    "P_B_not_A = 0.10  # Assumed probability that an employee is a smoker given that they do not use the plan\n",
    "\n",
    "# Calculate P(¬A), the probability that an employee does not use the health insurance plan\n",
    "P_not_A = 1 - P_A\n",
    "\n",
    "# Calculate P(B), the overall probability that an employee is a smoker\n",
    "P_B = P_B_given_A * P_A + P_B_not_A * P_not_A\n",
    "\n",
    "# Now we can calculate P(B|A) using Bayes' theorem\n",
    "# However, since we are given P(B|A) and we are looking for P(B), we can simplify our calculation\n",
    "P_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32bbbf34-3edf-4647-a5c5-a8b167cb4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032258064516128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate P(B|¬A) and P(¬A)\n",
    "P_B_not_A = 0.10  # Probability that an employee is a smoker given that they do not use the health insurance plan\n",
    "P_not_A = 1 - 0.70  # Probability that an employee does not use the health insurance plan\n",
    "\n",
    "# Calculate P(B)\n",
    "P_B = P_B_not_A * P_not_A + P_B_given_A * 0.70\n",
    "\n",
    "# Calculate P(B|A)\n",
    "P_B_given_A = (P_B_given_A * 0.70) / P_B\n",
    "P_B_given_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da8926-9d1b-4c26-ba43-9e5afae40053",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c84d0f-f284-473f-bc3b-07245258c1c4",
   "metadata": {},
   "source": [
    "Ans=Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm used in machine learning, particularly for text classification. The key difference between them lies in the type of data they are designed to handle.\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Data Type: Bernoulli Naive Bayes is suitable for binary-valued features, where each feature is a binary variable (0 or 1). It is commonly used for text classification problems where the presence or absence of words in a document is considered.\n",
    "Example Application: Document classification where the presence or absence of specific words is relevant (e.g., spam detection where words indicate spammy content).\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Data Type: Multinomial Naive Bayes is designed for discrete data, specifically for data with a count of occurrences (integer frequencies). It is commonly used for text classification where the features represent word counts or term frequencies.\n",
    "Example Application: Document classification where the frequency of words in a document is important (e.g., sentiment analysis using word counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb1c81-af64-4e1c-a4dc-ddbf20937f89",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe03d83-0c29-4b95-a6ec-0aa5402f63e8",
   "metadata": {},
   "source": [
    "Ans=Bernoulli Naive Bayes handles missing values by assuming that the missing values are equivalent to the feature being absent. In the context of Bernoulli Naive Bayes, features are binary, representing the presence (1) or absence (0) of a particular attribute.\n",
    "\n",
    "When dealing with missing values:\n",
    "\n",
    "Assumption of Absence: If a feature's value is missing, Bernoulli Naive Bayes assumes that the corresponding attribute is not present, and the feature is effectively treated as if it has a value of 0.\n",
    "\n",
    "Probability Calculation: When calculating probabilities during the classification process, the algorithm considers the probability of each feature being 0 (absent) or 1 (present). If a feature is missing, its contribution is treated as if it were 0.\n",
    "\n",
    "Bayesian Inference: The classification decision is made using Bayes' theorem, considering the probabilities of observed and missing features for each class. The class with the highest probability is chosen as the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee2412-e05d-4948-a030-3d3873417b33",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e325a-0d25-4304-8066-a3b010af8b8a",
   "metadata": {},
   "source": [
    "Ans=Yes, Gaussian Naive Bayes can be used for multi-class classification. The Gaussian Naive Bayes algorithm is an extension of the Naive Bayes algorithm that assumes that the features follow a Gaussian (normal) distribution. While it is commonly used for binary and two-class classification problems, it can also be adapted for multi-class classification scenarios.\n",
    "\n",
    "In the case of multi-class classification, the algorithm can be extended to handle more than two classes by using the \"one-vs-all\" (OvA) or \"one-vs-one\" (OvO) strategy. Here's a brief explanation of these strategies:\n",
    "\n",
    "One-vs-All (OvA): For \n",
    "�\n",
    "K classes, \n",
    "�\n",
    "K separate binary classifiers are trained. Each classifier is trained to distinguish between instances of one class and instances of all other classes. During prediction, the class that is assigned the highest probability by its respective classifier is chosen as the final predicted class.\n",
    "\n",
    "One-vs-One (OvO): For \n",
    "�\n",
    "K classes, \n",
    "�\n",
    "(\n",
    "�\n",
    "−\n",
    "1\n",
    ")\n",
    "2\n",
    "2\n",
    "K(K−1)\n",
    "​\n",
    "  binary classifiers are trained, each distinguishing between pairs of classes. During prediction, each classifier \"votes\" for a class, and the class with the most votes is chosen as the final predicted class.\n",
    "\n",
    "Both OvA and OvO strategies can be applied to Gaussian Naive Bayes to handle multi-class classification problems. The choice between these strategies often depends on factors such as the size of the dataset, the computational cost of training multiple classifiers, and the inherent characteristics of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169aa44-3b61-46ef-840b-3848015e91e0",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a3e5a-bc38-48d2-be66-548963e041f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426fa2cb-d7ea-439d-ab09-d0a4ae154295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spambase.names', 'spambase.DOCUMENTATION', 'spambase.data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the path to the zip file\n",
    "zip_file_path = 'spambase.zip'\n",
    "\n",
    "# Define the directory to extract the files to\n",
    "extract_folder = 'spambase_data'\n",
    "\n",
    "# Create a folder to extract the files to if it doesn't exist\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "# List the contents of the extraction folder\n",
    "extracted_files = os.listdir(extract_folder)\n",
    "extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcda84c3-2c5a-4708-a255-0a99f27403f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the spambase.data file\n",
    "file_path = 'spambase_data/spambase.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a46dd6-96cc-48cd-a0ce-31ba9752cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, header=None)\n",
    "df.head()\n",
    "column_names = [\n",
    "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    "    'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
    "    'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
    "    'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',\n",
    "    'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',\n",
    "    'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
    "    'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    "    'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[',\n",
    "    'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest',\n",
    "    'capital_run_length_total', 'is_spam'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af17ea1a-f840-4014-b59f-2348b0c1f84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, header=None, names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7f583-7ebc-449e-ae07-47fba6837b2e",
   "metadata": {},
   "source": [
    "The data has been successfully loaded with appropriate column names. The dataset contains features representing the frequency of certain words and characters in emails, as well as statistics on capital letters usage, with the last column indicating whether an email is spam (is_spam = 1) or not (is_spam = 0).\n",
    "\n",
    "Next, I will implement the Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using scikit-learn and evaluate them using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac626c40-34c0-419e-8089-05dcfa37f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1028c99-4b48-4093-aefd-8f53486acd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop('is_spam', axis=1)\n",
    "y = df['is_spam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30a84cc-be88-4a6b-950b-0ef25a582f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features to be between 0 and 1 for MultinomialNB\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f896c24-1918-4897-a153-211b7c2dde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5412af6-8003-4ceb-b7b9-aad209becdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation for each classifier\n",
    "bernoulli_scores = cross_val_score(bernoulli_nb, X, y, cv=10)\n",
    "multinomial_scores = cross_val_score(multinomial_nb, X_scaled, y, cv=10)\n",
    "gaussian_scores = cross_val_score(gaussian_nb, X, y, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550d5848-ca14-4aa8-87b0-c793ab536aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8839380364047911,\n",
       " 0.046658190126965045,\n",
       " 0.8748146750919551,\n",
       " 0.03282069829990614,\n",
       " 0.8217730830896915,\n",
       " 0.07715751692895616)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean accuracy and standard deviation for each classifier\n",
    "bernoulli_mean = bernoulli_scores.mean()\n",
    "bernoulli_std = bernoulli_scores.std()\n",
    "multinomial_mean = multinomial_scores.mean()\n",
    "multinomial_std = multinomial_scores.std()\n",
    "gaussian_mean = gaussian_scores.mean()\n",
    "gaussian_std = gaussian_scores.std()\n",
    "\n",
    "(bernoulli_mean, bernoulli_std, multinomial_mean, multinomial_std, gaussian_mean, gaussian_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4cc69-031e-4263-ab41-e8dd3edb6c7a",
   "metadata": {},
   "source": [
    "The 10-fold cross-validation results for the three Naive Bayes classifiers are as follows:\n",
    "\n",
    "Bernoulli Naive Bayes: Mean accuracy of 0.8839 with a standard deviation of 0.0467.\n",
    "\n",
    "Multinomial Naive Bayes: Mean accuracy of 0.8748 with a standard deviation of 0.0328.\n",
    "\n",
    "Gaussian Naive Bayes: Mean accuracy of 0.8218 with a standard deviation of 0.0772.\n",
    "\n",
    "These results indicate that the Bernoulli Naive Bayes classifier performs the best on this dataset in terms of mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4445b2f-b150-4d28-83e5-adb8374a22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2093bc98-b7f2-4f56-a423-375689c0280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation and obtain predictions for each fold\n",
    "bernoulli_predictions = cross_val_predict(bernoulli_nb, X, y, cv=10)\n",
    "multinomial_predictions = cross_val_predict(multinomial_nb, X_scaled, y, cv=10)\n",
    "gaussian_predictions = cross_val_predict(gaussian_nb, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf24ac8-576f-4d2f-bdf5-ad1de1b6ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for each classifier\n",
    "bernoulli_accuracy = accuracy_score(y, bernoulli_predictions)\n",
    "bernoulli_precision = precision_score(y, bernoulli_predictions)\n",
    "bernoulli_recall = recall_score(y, bernoulli_predictions)\n",
    "bernoulli_f1 = f1_score(y, bernoulli_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff9b860-1200-4d03-ba02-5b0c3d9298e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_accuracy = accuracy_score(y, multinomial_predictions)\n",
    "multinomial_precision = precision_score(y, multinomial_predictions)\n",
    "multinomial_recall = recall_score(y, multinomial_predictions)\n",
    "multinomial_f1 = f1_score(y, multinomial_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f3bf8da-d8da-456b-9e40-2cd31d8945d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_accuracy = accuracy_score(y, gaussian_predictions)\n",
    "gaussian_precision = precision_score(y, gaussian_predictions)\n",
    "gaussian_recall = recall_score(y, gaussian_predictions)\n",
    "gaussian_f1 = f1_score(y, gaussian_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a129ae79-dbb2-4e34-99b4-84e01bd0b3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8839382742881983,\n",
       " 0.8813357185450209,\n",
       " 0.815223386651958,\n",
       " 0.8469914040114614,\n",
       " 0.8748098239513149,\n",
       " 0.8992898644286637,\n",
       " 0.7683397683397684,\n",
       " 0.8286734086853063,\n",
       " 0.8217778743751358,\n",
       " 0.7004440855874041,\n",
       " 0.9569773855488142,\n",
       " 0.8088578088578089)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bernoulli_accuracy, bernoulli_precision, bernoulli_recall, bernoulli_f1, multinomial_accuracy, multinomial_precision, multinomial_recall, multinomial_f1, gaussian_accuracy, gaussian_precision, gaussian_recall, gaussian_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae88903-76a7-4cc9-8b5b-9d146ab6ea33",
   "metadata": {},
   "source": [
    "The performance metrics for each classifier are as follows:\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Accuracy: 0.8839382742881983\n",
    "Precision: 0.8813357185450209\n",
    "Recall: 0.815223386651958\n",
    "F1 score: 0.8469914040114614\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Accuracy: 0.8748098239513149\n",
    "Precision: 0.8992898644286637\n",
    "Recall: 0.7683397683397684\n",
    "F1 score: 0.8286734086853063\n",
    "Gaussian Naive Bayes:\n",
    "\n",
    "Accuracy: 0.8217778743751358\n",
    "Precision: 0.7004440855874041\n",
    "Recall: 0.9569773855488142\n",
    "F1 score: 0.8088578088578089\n",
    "These metrics provide a comprehensive view of each model's performance, considering both the positive and negative classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae0280-ed6e-4e69-be5b-8b2ab9fd8c7f",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "The Bernoulli Naive Bayes classifier performed the best in terms of accuracy and F1 score, while the Multinomial Naive Bayes classifier had the highest precision. The performance of the Gaussian Naive Bayes classifier was lower compared to the other two classifiers.\n",
    "\n",
    "The reason for the superior performance of the Bernoulli Naive Bayes classifier could be attributed to the nature of the dataset. The Bernoulli Naive Bayes classifier is well-suited for binary feature data, which aligns with the binary nature of the spam classification task. On the other hand, the Multinomial Naive Bayes classifier, which is designed for count-based features, also performed well due to the nature of the word frequency features in the dataset.\n",
    "\n",
    "One limitation of Naive Bayes classifiers is the assumption of independence between features, which may not hold true in real-world data. Additionally, Naive Bayes classifiers may not perform well with highly correlated features, and they are sensitive to the presence of irrelevant or noisy features.\n",
    "\n",
    "Overall, the results indicate that the choice of Naive Bayes classifier should be based on the nature of the features and the specific characteristics of the dataset. In future work, it would be beneficial to explore feature engineering techniques to improve the performance of the classifiers and to consider the use of ensemble methods to further enhance the predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74747afe-cdfd-42c9-84f4-d6f9c1e2b7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
