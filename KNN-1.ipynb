{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872ee9ee-02d3-4e34-a425-c6d8b59b062c",
   "metadata": {},
   "source": [
    "## Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8eb870-aa38-4ecb-a58e-b7ca50a3f92a",
   "metadata": {},
   "source": [
    "Ans-K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining, and intrusion detection.\n",
    "\n",
    "It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as GMM, which assume a Gaussian distribution of the given data). We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b88748-c038-4252-970e-1a32b6b58d0a",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0c728-d97e-4eb1-b811-6cb0087571ce",
   "metadata": {},
   "source": [
    "Ans-The value of k is very crucial in the KNN algorithm to define the number of neighbors in the algorithm. The value of k in the k-nearest neighbors (k-NN) algorithm should be chosen based on the input data. If the input data has more outliers or noise, a higher value of k would be better. It is recommended to choose an odd value for k to avoid ties in classification. Cross-validation methods can help in selecting the best k value for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080e47a-634d-4f8e-89f8-60c78580c5f7",
   "metadata": {},
   "source": [
    "## Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14cf68-2518-4e5d-9097-da6021ed1f77",
   "metadata": {},
   "source": [
    "Ans-Regression Algorithm:\n",
    "1.In Regression, the output variable must be of continuous nature or real value.\n",
    "2.The task of the regression algorithm is to map the input value (x) with the continuous output variable(y).\n",
    "3.Regression Algorithms are used with continuous data.\n",
    "4.In Regression, we try to find the best fit line, which can predict the output more accurately.\n",
    "5.Regression algorithms can be used to solve the regression problems such as Weather Prediction, House price prediction, etc.\n",
    "6.The regression Algorithm can be further divided into Linear and Non-linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa0f6f-0b78-4b35-82b1-0170f1102017",
   "metadata": {},
   "source": [
    "Classification Algorithm:\n",
    "1.In Classification, the output variable must be a discrete value.\n",
    "2.The task of the classification algorithm is to map the input value(x) with the discrete output variable(y).\n",
    "3.Classification Algorithms are used with discrete data.\n",
    "4.In Classification, we try to find the decision boundary, which can divide the dataset into different classes.\n",
    "5.Classification Algorithms can be used to solve classification problems such as Identification of spam emails, Speech Recognition, Identification of cancer cells, etc.\n",
    "6.The Classification algorithms can be divided into Binary Classifier and Multi-class Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5dc62-28d6-402e-b10f-1d8c964dd7af",
   "metadata": {},
   "source": [
    "## Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728964b-8a58-4d67-a362-c6ae20cb2163",
   "metadata": {},
   "source": [
    "Ans-Determine the number of nearest neighbours (K values).\n",
    "\n",
    "Compute the distance between test sample and all the training samples.\n",
    "\n",
    "Sort the distance and determine nearest neighbours based on the K-th minimum distance.\n",
    "\n",
    "Assemble the categories of the nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895e54f-182b-4c11-bf55-dedde720a055",
   "metadata": {},
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff3bda-fa9a-41e9-a1f8-457ce10c0aa4",
   "metadata": {},
   "source": [
    "Ans-The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size of your data set must also grow exponentially in order to keep the same density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04406c72-f2a6-4387-8bd8-7e0a594cced0",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438571af-2206-494f-981c-b8268f8806b6",
   "metadata": {},
   "source": [
    "Ans-KNN is an algorithm that is useful for matching a point with its closest k neighbors in a multi-dimensional space. It can be used for data that are continuous, discrete, ordinal and categorical which makes it particularly useful for dealing with all kind of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befd5fc-5d1d-452a-a622-19b04f0d6710",
   "metadata": {},
   "source": [
    "df.isnull().sum()\n",
    "#missing values in Item_weight and Outlet_size needs to be imputed\n",
    "mean = df['Item_Weight'].mean() #imputing item_weight with mean\n",
    "df['Item_Weight'].fillna(mean, inplace =True)\n",
    "\n",
    "mode = df['Outlet_Size'].mode() #imputing outlet size with mode\n",
    "df['Outlet_Size'].fillna(mode[0], inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21554b2-a576-4f42-b11d-0ec04f92eb32",
   "metadata": {},
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd9e50-1536-4d23-a944-faff14ceace1",
   "metadata": {},
   "source": [
    "ANS-KNN (K-Nearest Neighbors) Classifier is a type of machine learning algorithm used for classification tasks. It is a non-parametric algorithm, which means it does not make any assumptions about the underlying distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385b69a-2778-4b53-9d6b-284c83aeb97f",
   "metadata": {},
   "source": [
    "## Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde9867-1f69-4e06-b35a-a9c494e6ed41",
   "metadata": {},
   "source": [
    "ANS-It has advantages - nonparametric architecture, simple and powerful, requires no traning time, but it also has disadvantage - memory intensive, classification and estimation are slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07a693-6658-48f9-800c-e0dba71b12bd",
   "metadata": {},
   "source": [
    "## Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f934de-2912-442f-8c05-9ca0ad93edff",
   "metadata": {},
   "source": [
    "Ans-Distance Metrics Used in KNN Algorithm\n",
    "As we know that the KNN algorithm helps us identify the nearest points or the groups for a query point. But to determine the closest groups or the nearest points for a query point we need some metric. For this purpose, we use below distance metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb884ff6-3ee9-4920-98c4-f38c71954a13",
   "metadata": {},
   "source": [
    "Euclidean Distance\"\n",
    "This is nothing but the cartesian distance between the two points which are in the plane/hyperplane. Euclidean distance can also be visualized as the length of the straight line that joins the two points which are into consideration. This metric helps us calculate the net displacement done between the two states of an object.\n",
    "d\\left ( x,y \\right )=\\sqrt{\\sum_{i=1}^{n}\\left ( x_i-y_i \\right )^2}\n",
    "\n",
    "Manhattan Distance\n",
    "This distance metric is generally used when we are interested in the total distance traveled by the object instead of the displacement. This metric is calculated by summing the absolute difference between the coordinates of the points in n-dimensions.\n",
    "\n",
    "d\\left ( x,y \\right )={\\sum_{i=1}^{n}\\left | x_i-y_i \\right |}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a666b27-a5bc-4ac6-acfb-1406b8c99f86",
   "metadata": {},
   "source": [
    "## Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983de609-6c74-4253-8ffb-a293ff1d2a4e",
   "metadata": {},
   "source": [
    "ANS-Feature scaling is essential for machine learning algorithms that calculate distances between data. If not scaled, the feature with a higher value range starts dominating when calculating distances. KNN which uses Euclidean distance is one such algorithm which essentially require scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1e22b-d80e-40ed-bfb1-a6b4826239a1",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f599c-c40c-4173-9e01-5dad55f88318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544caa88-cc12-4f29-8ba2-b9f02c684d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f12ae8-d2af-412c-bd01-fa702edb436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
